version: "3.7"

services:
  jupyter:
    image: jupyter/all-spark-notebook
    environment:
      JUPYTER_ENABLE_LAB: "yes"
    ports:
      - "8888:8888"
    volumes:
      - ./data:/home/jovyan/work
    networks:
      - airflow

  # zookeeper:
  #   image: confluentinc/cp-zookeeper:7.0.1
  #   container_name: zookeeper
  #   environment:
  #     ZOOKEEPER_CLIENT_PORT: 2181
  #     ZOOKEEPER_TICK_TIME: 2000
  #   networks:
  #     - airflow

  # broker:
  #   image: confluentinc/cp-kafka:7.0.1
  #   container_name: broker
  #   ports:
  #     - "9092:9092"
  #     - "29092:29092"
  #   depends_on:
  #     - zookeeper
  #   environment:
  #     KAFKA_BROKER_ID: 1
  #     KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
  #     KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
  #     KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://broker:29092
  #     KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
  #     KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
  #     KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
  #   networks:
  #     - airflow

  # schemaregistry:
  #   image: confluentinc/cp-schema-registry:7.2.1
  #   ports:
  #     - 8085:8085
  #   depends_on:
  #     - broker
  #   environment:
  #     SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: PLAINTEXT://broker:29092
  #     SCHEMA_REGISTRY_KAFKASTORE_SECURITY_PROTOCOL: PLAINTEXT
  #     SCHEMA_REGISTRY_HOST_NAME: schemaregistry
  #     SCHEMA_REGISTRY_LISTENERS: http://schemaregistry:8085

  #     SCHEMA_REGISTRY_SCHEMA_REGISTRY_INTER_INSTANCE_PROTOCOL: "http"
  #     SCHEMA_REGISTRY_LOG4J_ROOT_LOGLEVEL: INFO
  #     SCHEMA_REGISTRY_KAFKASTORE_TOPIC: _schemas
  #   networks:
  #     - airflow

  # kafka-ui:
  #   container_name: kafka-ui
  #   image: provectuslabs/kafka-ui:latest
  #   ports:
  #     - 8081:8080
  #   depends_on:
  #     - broker
  #     - schemaregistry
  #   environment:
  #     KAFKA_CLUSTERS_0_NAME: local
  #     KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: broker:29092
  #     KAFKA_CLUSTERS_0_METRICS_PORT: 9997
  #     KAFKA_CLUSTERS_0_SCHEMAREGISTRY: http://schemaregistry:8085
  #     DYNAMIC_CONFIG_ENABLED: 'true'
  #   networks:
  #     - airflow

  minio:
    restart: always
    image: minio/minio
    volumes:
      - ./minio_data:/data
    ports:
      - "${MINIO_PORT}:9000"
      - "${MINIO_CONSOLE_PORT}:9001"
    networks:
      - airflow
    environment:
      - MINIO_ROOT_USER=${MINIO_ROOT_USER}
      - MINIO_ROOT_PASSWORD=${MINIO_ROOT_PASSWORD}
      - MINIO_ADDRESS=${MINIO_ADDRESS}
      - MINIO_PORT=${MINIO_PORT}
      - MINIO_STORAGE_USE_HTTPS=${MINIO_STORAGE_USE_HTTPS}
      - MINIO_CONSOLE_ADDRESS=${MINIO_CONSOLE_ADDRESS}
      - MINIO_DEFAULT_BUCKETS=${MLFLOW_BUCKET_NAME}
    command: server /data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3

  mlflow:
    # restart: always
    build: ./dockerfiles/mlflow
    image: mlflow
    ports:
      - "${MLFLOW_PORT}:5000"
    networks:
      - airflow
    environment:
      - AWS_ACCESS_KEY_ID=${MINIO_ACCESS_KEY}
      - AWS_SECRET_ACCESS_KEY=${MINIO_SECRET_ACCESS_KEY}
      - MLFLOW_S3_ENDPOINT_URL=http://s3:${MINIO_PORT}
      - MLFLOW_S3_IGNORE_TLS=true
    command: >
      mlflow server
      --backend-store-uri postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:${POSTGRES_PORT}/mlflow
      --host 0.0.0.0
      --serve-artifacts
      --artifacts-destination s3://${MLFLOW_BUCKET_NAME}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:${MLFLOW_PORT}/"]
      interval: 30s
      timeout: 10s
      retries: 3

networks:
  airflow:
    name: airflow-dags_487b6a_airflow
    external: true

volumes:
  pgdata2:
  minio_data:
